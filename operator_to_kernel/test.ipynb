{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k8smaster/miniconda3/envs/k8s/lib/python3.10/site-packages/torch/profiler/profiler.py:445: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "  warn(\"Profiler won't be using warmup, this can skew profiler results\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理文件 resnet18_forward.json...\n",
      "文件 resnet18_forward.json 已成功转化为 log_csv/resnet18_forward 目录下的csv\n",
      "正在处理文件 resnet18.json...\n",
      "文件 resnet18.json 已成功转化为 log_csv/resnet18 目录下的csv\n",
      "正在处理文件 VGG16.json...\n",
      "文件 VGG16.json 已成功转化为 log_csv/VGG16 目录下的csv\n",
      "所有文件转换完成。\n",
      "Profiling completed. Trace log saved to './log/resnet18_forward.json'\n",
      "CSV files saved to 'log_csv'\n",
      "正在处理文件 resnet18_backward.json...\n",
      "文件 resnet18_backward.json 已成功转化为 log_csv/resnet18_backward 目录下的csv\n",
      "正在处理文件 resnet18_forward.json...\n",
      "文件 resnet18_forward.json 已成功转化为 log_csv/resnet18_forward 目录下的csv\n",
      "正在处理文件 resnet18.json...\n",
      "文件 resnet18.json 已成功转化为 log_csv/resnet18 目录下的csv\n",
      "正在处理文件 VGG16.json...\n",
      "文件 VGG16.json 已成功转化为 log_csv/VGG16 目录下的csv\n",
      "所有文件转换完成。\n",
      "Profiling completed. Trace log saved to './log/resnet18_backward.json'\n",
      "CSV files saved to 'log_csv'\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.fx as fx\n",
    "\n",
    "from model_static_graph import extract_graph, draw_graph\n",
    "from pytorch_tracing import py_tracing_forward, py_tracing_backward\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "model = torchvision.models.resnet18().cuda()\n",
    "input_data = torch.randn(5, 3, 224, 224).cuda()\n",
    "model_name='resnet18'\n",
    "\n",
    "static_graph,name_module,adj=extract_graph(model)\n",
    "draw_graph(adj,name_module, model_name=model_name)\n",
    "#draw_graph(adj,name_module, model_name=model_name,t=1)\n",
    "\n",
    "py_tracing_forward(model, input_data, model_name=model_name)\n",
    "py_tracing_backward(model, input_data, model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cpu=pd.read_csv('log_csv/resnet18_forward/cpu_op.csv')\n",
    "cuda=pd.read_csv('log_csv/resnet18_forward/cuda_runtime.csv')\n",
    "kernel=pd.read_csv('log_csv/resnet18_forward/kernel.csv')\n",
    "cuda=cuda[cuda['name'].str.contains('cudaLaunchKernel')].reset_index(drop=True)\n",
    "\n",
    "kernel_list=set(kernel['name'].to_list())\n",
    "#提出cuda里的correlation和External id 两列\n",
    "cuda=cuda[['correlation','External id']]\n",
    "op_kernel={}\n",
    "for i in range(len(cuda)):\n",
    "    corr=cuda.loc[i,'correlation']\n",
    "    ex_id=cuda.loc[i,'External id']\n",
    "    kernel_name=kernel[kernel['correlation']==corr]['name'].values[0]\n",
    "    op_name=cpu[cpu['External id']==ex_id]['name'].values[0]\n",
    "    if op_name not in op_kernel:\n",
    "        op_kernel[op_name]=set()\n",
    "    op_kernel[op_name].add(kernel_name)\n",
    "\n",
    "len(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::cudnn_convolution 20 kernel_sum 65\n",
      "     void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params) 1\n",
      "     _5x_cudnn_ampere_scudnn_128x64_relu_interior_nn_v1 1\n",
      "     void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, false, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, bool, int, int) 1\n",
      "     void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*) 34\n",
      "     sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn 4\n",
      "     sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize64x32x64_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn 1\n",
      "     _5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1 1\n",
      "     void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams) 2\n",
      "     void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4::Params) 4\n",
      "     sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn 3\n",
      "     sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn 3\n",
      "     sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn 1\n",
      "     void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*) 9\n",
      "aten::add_ 28 kernel_sum 28\n",
      "     void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>) 8\n",
      "     void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>) 20\n",
      "aten::cudnn_batch_norm 20 kernel_sum 20\n",
      "     void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 128, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) 4\n",
      "     void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) 1\n",
      "     void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>) 15\n",
      "aten::clamp_min_ 17 kernel_sum 17\n",
      "     void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>) 17\n",
      "aten::max_pool2d_with_indices 1 kernel_sum 1\n",
      "     void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*) 1\n",
      "aten::mean 1 kernel_sum 1\n",
      "     void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4>) 1\n",
      "aten::addmm 1 kernel_sum 1\n",
      "     void gemmSN_TN_kernel<float, 128, 16, 2, 4, 6, 7, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>) 1\n",
      "total kernel 133\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "for key in op_kernel:\n",
    "    sum=0\n",
    "    for kernel_name in op_kernel[key]:\n",
    "        sum+=len(kernel[kernel['name']==kernel_name])\n",
    "    print(key,len(cpu[cpu['name']==key]),\"kernel_sum\",sum)\n",
    "    for kernel_name in op_kernel[key]:\n",
    "        print(\"    \",kernel_name,len(kernel[kernel['name']==kernel_name]))\n",
    "    total+=sum\n",
    "\n",
    "print(\"total kernel\",total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#比较op_kernel里每个key的set是否有交集\n",
    "for key1 in op_kernel:\n",
    "    for key2 in op_kernel:\n",
    "        if key1!=key2:\n",
    "            if len(op_kernel[key1]&op_kernel[key2])>0:\n",
    "                print(key1,key2,op_kernel[key1]&op_kernel[key2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tracer = fx.Tracer()\n",
    "# graph = tracer.trace(model)\n",
    "\n",
    "# # 创建 GraphModule\n",
    "# graph_module = fx.GraphModule(model, graph)\n",
    "# #graph_module\n",
    "# #输出fx.里的方法\n",
    "# dir(fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traced_model = fx.symbolic_trace(model)\n",
    "# graph_module.print_readable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k8s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
