ts,block,tid,queued,dur,name,context,device,registers per thread,shared memory,stream,correlation,ph,blocks per SM,pid,cat,warps per SM,grid,est. achieved occupancy %,External id
6444517260223.318,"[256, 1, 1]",7,0,1.824,"void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams)",1,0,16,0,7,19,X,0.595238,0,kernel,4.761905,"[50, 1, 1]",10,5
6444517260244.854,"[128, 1, 1]",7,0,82.016,_5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1,1,0,128,16384,7,22,X,5.833333,0,kernel,23.333334,"[490, 1, 1]",33,5
6444517260418.614,"[128, 1, 1]",7,0,1.952,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,30,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,6
6444517260808.312,"[512, 1, 1]",7,0,87.904,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,40,144,7,86,X,0.761905,0,kernel,12.190476,"[64, 1, 1]",25,9
6444517260928.12,"[128, 1, 1]",7,0,58.112,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,93,X,93.333336,0,kernel,373.333344,"[7840, 1, 1]",100,18
6444517261188.376,"[256, 1, 1]",7,0,54.304,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,26,0,7,114,X,46.666668,0,kernel,373.333344,"[3920, 1, 1]",100,20
6444517261365.369,"[256, 1, 1]",7,0,13.056,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,132,X,11.666667,0,kernel,93.333336,"[98, 2, 5]",100,24
6444517261379.193,"[256, 1, 1]",7,0,3.2,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,134,X,1.52381,0,kernel,12.190476,"[1, 2, 64]",25,24
6444517261405.816,"[128, 1, 1]",7,0,40.801,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,228,98304,7,139,X,1.464286,0,kernel,5.857143,"[1, 123, 1]",0,24
6444517261493.401,"[128, 1, 1]",7,0,1.824,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,148,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,25
6444517261683.705,"[512, 1, 1]",7,0,15.392,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 128, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,40,144,7,200,X,0.761905,0,kernel,12.190476,"[64, 1, 1]",25,28
6444517261745.401,"[128, 1, 1]",7,0,4.096,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,207,X,23.333334,0,kernel,93.333336,"[1960, 1, 1]",100,37
6444517261984.09,"[256, 1, 1]",7,0,8.928,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,231,X,11.666667,0,kernel,93.333336,"[98, 2, 5]",100,41
6444517261995.29,"[256, 1, 1]",7,0,3.168,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,233,X,1.52381,0,kernel,12.190476,"[1, 2, 64]",25,41
6444517262014.714,"[128, 1, 1]",7,0,40.032,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,228,98304,7,238,X,1.464286,0,kernel,5.857143,"[1, 123, 1]",0,41
6444517262108.827,"[128, 1, 1]",7,0,1.823,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,247,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,42
6444517262262.811,"[512, 1, 1]",7,0,15.872,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 128, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,40,144,7,299,X,0.761905,0,kernel,12.190476,"[64, 1, 1]",25,45
6444517262300.699,"[128, 1, 1]",7,0,15.04,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",1,0,22,0,7,305,X,23.333334,0,kernel,93.333336,"[1960, 1, 1]",100,53
6444517262348.795,"[128, 1, 1]",7,0,4.16,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,312,X,23.333334,0,kernel,93.333336,"[1960, 1, 1]",100,55
6444517262466.204,"[256, 1, 1]",7,0,8.415,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,332,X,11.666667,0,kernel,93.333336,"[98, 2, 5]",100,59
6444517262476.636,"[256, 1, 1]",7,0,3.232,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,334,X,1.52381,0,kernel,12.190476,"[1, 2, 64]",25,59
6444517262492.604,"[128, 1, 1]",7,0,41.632,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,228,98304,7,339,X,1.464286,0,kernel,5.857143,"[1, 123, 1]",0,59
6444517262563.324,"[128, 1, 1]",7,0,1.952,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,348,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,60
6444517262697.532,"[512, 1, 1]",7,0,14.688,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 128, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,40,144,7,400,X,0.761905,0,kernel,12.190476,"[64, 1, 1]",25,63
6444517262751.452,"[128, 1, 1]",7,0,4.224,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,407,X,23.333334,0,kernel,93.333336,"[1960, 1, 1]",100,72
6444517262852.22,"[256, 1, 1]",7,0,8.128,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,427,X,11.666667,0,kernel,93.333336,"[98, 2, 5]",100,76
6444517262862.3,"[256, 1, 1]",7,0,3.36,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,429,X,1.52381,0,kernel,12.190476,"[1, 2, 64]",25,76
6444517262877.404,"[128, 1, 1]",7,0,40.704,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,228,98304,7,434,X,1.464286,0,kernel,5.857143,"[1, 123, 1]",0,76
6444517262941.18,"[128, 1, 1]",7,0,1.888,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,443,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,77
6444517263073.757,"[512, 1, 1]",7,0,14.784,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 128, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,40,144,7,495,X,0.761905,0,kernel,12.190476,"[64, 1, 1]",25,80
6444517263105.981,"[128, 1, 1]",7,0,14.624,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",1,0,22,0,7,501,X,23.333334,0,kernel,93.333336,"[1960, 1, 1]",100,88
6444517263147.581,"[128, 1, 1]",7,0,4.0,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,508,X,23.333334,0,kernel,93.333336,"[1960, 1, 1]",100,90
6444517263401.533,"[256, 1, 1]",7,0,8.257,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,532,X,11.666667,0,kernel,93.333336,"[98, 2, 5]",100,94
6444517263412.67,"[256, 1, 1]",7,0,4.48,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,534,X,3.047619,0,kernel,24.380953,"[1, 2, 128]",51,94
6444517263426.846,"[128, 1, 1]",7,0,17.216,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params),1,0,162,73728,7,538,X,0.738095,0,kernel,2.952381,"[62, 1, 1]",0,94
6444517263444.99,"[256, 1, 1]",7,0,2.976,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,542,X,5.952381,0,kernel,47.619049,"[25, 4, 5]",99,94
6444517263522.59,"[128, 1, 1]",7,0,1.888,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,550,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,95
6444517263674.879,"[512, 1, 1]",7,0,6.367,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,16528,7,603,X,1.52381,0,kernel,24.380953,"[128, 1, 1]",51,98
6444517263731.679,"[128, 1, 1]",7,0,2.496,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,611,X,11.666667,0,kernel,46.666668,"[980, 1, 1]",97,107
6444517263842.111,"[256, 1, 1]",7,0,2.976,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,631,X,5.952381,0,kernel,47.619049,"[25, 4, 5]",99,111
6444517263849.887,"[256, 1, 1]",7,0,4.544,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,633,X,6.095238,0,kernel,48.761906,"[1, 4, 128]",100,111
6444517263869.599,"[128, 1, 1]",7,0,51.808,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,232,65536,7,638,X,0.369048,0,kernel,1.47619,"[1, 31, 1]",0,111
6444517263939.999,"[128, 1, 1]",7,0,1.568,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,647,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,112
6444517264077.599,"[512, 1, 1]",7,0,6.144,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,16528,7,700,X,1.52381,0,kernel,24.380953,"[128, 1, 1]",51,115
6444517264202.88,"[256, 1, 1]",7,0,1.759,"void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams)",1,0,16,0,7,719,X,0.047619,0,kernel,0.380952,"[4, 1, 1]",1,126
6444517264220.735,"[128, 1, 1]",7,0,14.849,_5x_cudnn_ampere_scudnn_128x64_relu_interior_nn_v1,1,0,128,16384,7,722,X,0.738095,0,kernel,2.952381,"[31, 2, 1]",6,126
6444517264284.64,"[128, 1, 1]",7,0,1.44,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,730,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,127
6444517264418.784,"[512, 1, 1]",7,0,6.016,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,16528,7,783,X,1.52381,0,kernel,24.380953,"[128, 1, 1]",51,130
6444517264453.344,"[128, 1, 1]",7,0,7.552,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",1,0,22,0,7,790,X,11.666667,0,kernel,46.666668,"[980, 1, 1]",97,138
6444517264496.864,"[128, 1, 1]",7,0,2.592,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,797,X,11.666667,0,kernel,46.666668,"[980, 1, 1]",97,140
6444517264618.176,"[256, 1, 1]",7,0,3.2,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,817,X,5.952381,0,kernel,47.619049,"[25, 4, 5]",99,144
6444517264628.737,"[256, 1, 1]",7,0,4.48,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,819,X,6.095238,0,kernel,48.761906,"[1, 4, 128]",100,144
6444517264647.809,"[128, 1, 1]",7,0,51.04,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,232,65536,7,824,X,0.369048,0,kernel,1.47619,"[1, 31, 1]",0,144
6444517264713.089,"[128, 1, 1]",7,0,1.504,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,833,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,145
6444517264843.329,"[512, 1, 1]",7,0,6.208,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,16528,7,886,X,1.52381,0,kernel,24.380953,"[128, 1, 1]",51,148
6444517264893.697,"[128, 1, 1]",7,0,2.56,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,894,X,11.666667,0,kernel,46.666668,"[980, 1, 1]",97,157
6444517265003.138,"[256, 1, 1]",7,0,2.944,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,914,X,5.952381,0,kernel,47.619049,"[25, 4, 5]",99,161
6444517265011.169,"[256, 1, 1]",7,0,4.417,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,916,X,6.095238,0,kernel,48.761906,"[1, 4, 128]",100,161
6444517265027.874,"[128, 1, 1]",7,0,50.656,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,232,65536,7,921,X,0.369048,0,kernel,1.47619,"[1, 31, 1]",0,161
6444517265092.546,"[128, 1, 1]",7,0,1.536,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,930,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,162
6444517265227.01,"[512, 1, 1]",7,0,6.08,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,16528,7,983,X,1.52381,0,kernel,24.380953,"[128, 1, 1]",51,165
6444517265259.202,"[128, 1, 1]",7,0,5.536,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",1,0,22,0,7,990,X,11.666667,0,kernel,46.666668,"[980, 1, 1]",97,173
6444517265301.026,"[128, 1, 1]",7,0,2.56,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,997,X,11.666667,0,kernel,46.666668,"[980, 1, 1]",97,175
6444517265579.395,"[256, 1, 1]",7,0,3.552,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1021,X,5.952381,0,kernel,47.619049,"[25, 4, 5]",99,179
6444517265589.059,"[256, 1, 1]",7,0,6.784,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1023,X,12.190476,0,kernel,97.523811,"[1, 4, 256]",100,179
6444517265603.587,"[128, 1, 1]",7,0,17.28,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4::Params),1,0,118,81920,7,1027,X,0.761905,0,kernel,3.047619,"[64, 1, 1]",0,179
6444517265621.635,"[256, 1, 1]",7,0,3.136,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1031,X,3.333333,0,kernel,26.666666,"[7, 8, 5]",56,179
6444517265706.275,"[128, 1, 1]",7,0,1.472,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1039,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,180
6444517265857.155,"[512, 1, 1]",7,0,6.561,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,4240,7,1092,X,3.047619,0,kernel,48.761906,"[256, 1, 1]",100,183
6444517265912.1,"[128, 1, 1]",7,0,2.144,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1100,X,5.833333,0,kernel,23.333334,"[490, 1, 1]",49,192
6444517266160.58,"[256, 1, 1]",7,0,2.496,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1124,X,3.333333,0,kernel,26.666666,"[7, 8, 5]",56,196
6444517266168.42,"[256, 1, 1]",7,0,10.208,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1126,X,24.380953,0,kernel,195.047623,"[1, 8, 256]",100,196
6444517266183.108,"[128, 1, 1]",7,0,27.041,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4::Params),1,0,118,81920,7,1130,X,0.761905,0,kernel,3.047619,"[64, 1, 1]",0,196
6444517266210.948,"[256, 1, 1]",7,0,3.105,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1134,X,3.333333,0,kernel,26.666666,"[7, 8, 5]",56,196
6444517266278.053,"[128, 1, 1]",7,0,1.472,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1142,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,197
6444517266424.357,"[512, 1, 1]",7,0,6.592,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,4240,7,1195,X,3.047619,0,kernel,48.761906,"[256, 1, 1]",100,200
6444517266685.734,"[8, 8, 1]",7,0,15.136,"void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, false, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, bool, int, int)",1,0,63,2304,7,1218,X,2.952381,0,kernel,5.904762,"[31, 8, 1]",12,211
6444517266766.214,"[128, 1, 1]",7,0,1.504,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1226,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,212
6444517266926.054,"[512, 1, 1]",7,0,6.592,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,4240,7,1279,X,3.047619,0,kernel,48.761906,"[256, 1, 1]",100,215
6444517266962.023,"[128, 1, 1]",7,0,2.399,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",1,0,22,0,7,1286,X,5.833333,0,kernel,23.333334,"[490, 1, 1]",49,223
6444517267006.631,"[128, 1, 1]",7,0,2.048,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1293,X,5.833333,0,kernel,23.333334,"[490, 1, 1]",49,225
6444517267118.47,"[256, 1, 1]",7,0,2.528,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1313,X,3.333333,0,kernel,26.666666,"[7, 8, 5]",56,229
6444517267126.342,"[256, 1, 1]",7,0,10.145,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1315,X,24.380953,0,kernel,195.047623,"[1, 8, 256]",100,229
6444517267140.167,"[128, 1, 1]",7,0,27.072,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4::Params),1,0,118,81920,7,1319,X,0.761905,0,kernel,3.047619,"[64, 1, 1]",0,229
6444517267168.007,"[256, 1, 1]",7,0,2.624,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1323,X,3.333333,0,kernel,26.666666,"[7, 8, 5]",56,229
6444517267212.135,"[128, 1, 1]",7,0,1.472,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1331,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,230
6444517267488.583,"[512, 1, 1]",7,0,6.881,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,4240,7,1388,X,3.047619,0,kernel,48.761906,"[256, 1, 1]",100,233
6444517267555.304,"[128, 1, 1]",7,0,2.048,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1396,X,5.833333,0,kernel,23.333334,"[490, 1, 1]",49,242
6444517267679.208,"[256, 1, 1]",7,0,2.496,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1416,X,3.333333,0,kernel,26.666666,"[7, 8, 5]",56,246
6444517267686.952,"[256, 1, 1]",7,0,10.4,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1418,X,24.380953,0,kernel,195.047623,"[1, 8, 256]",100,246
6444517267700.68,"[128, 1, 1]",7,0,27.04,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4::Params),1,0,118,81920,7,1422,X,0.761905,0,kernel,3.047619,"[64, 1, 1]",0,246
6444517267728.392,"[256, 1, 1]",7,0,2.592,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1426,X,3.333333,0,kernel,26.666666,"[7, 8, 5]",56,246
6444517267776.425,"[128, 1, 1]",7,0,1.535,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1434,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,247
6444517268037.065,"[512, 1, 1]",7,0,6.784,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,4240,7,1491,X,3.047619,0,kernel,48.761906,"[256, 1, 1]",100,250
6444517268079.209,"[128, 1, 1]",7,0,3.616,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",1,0,22,0,7,1498,X,5.833333,0,kernel,23.333334,"[490, 1, 1]",49,258
6444517268128.233,"[128, 1, 1]",7,0,2.113,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1505,X,5.833333,0,kernel,23.333334,"[490, 1, 1]",49,260
6444517268261.642,"[256, 1, 1]",7,0,2.496,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1525,X,3.333333,0,kernel,26.666666,"[7, 8, 5]",56,264
6444517268269.322,"[256, 1, 1]",7,0,17.92,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1527,X,48.761906,0,kernel,390.095245,"[1, 8, 512]",100,264
6444517268302.378,"[128, 1, 1]",7,0,34.816,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize64x32x64_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,122,99328,7,1533,X,1.52381,0,kernel,6.095238,"[16, 4, 2]",0,264
6444517268372.138,"[128, 1, 1]",7,0,1.824,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1542,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,265
6444517268511.69,"[512, 1, 1]",7,0,9.12,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,2192,7,1595,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,268
6444517268562.954,"[128, 1, 1]",7,0,1.696,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1603,X,2.916667,0,kernel,11.666667,"[245, 1, 1]",24,277
6444517268669.418,"[256, 1, 1]",7,0,2.208,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1623,X,1.904762,0,kernel,15.238095,"[2, 16, 5]",32,281
6444517268677.706,"[256, 1, 1]",7,0,33.537,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1625,X,97.523811,0,kernel,780.190491,"[1, 16, 512]",100,281
6444517268713.643,"[128, 1, 1]",7,0,53.663,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,198,100352,7,1631,X,0.380952,0,kernel,1.52381,"[8, 2, 2]",0,281
6444517268768.011,"[256, 1, 1]",7,0,2.688,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1634,X,1.904762,0,kernel,15.238095,"[2, 16, 5]",32,281
6444517268781.61,"[128, 1, 1]",7,0,1.92,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1642,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,282
6444517269055.339,"[512, 1, 1]",7,0,8.545,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,2192,7,1699,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,285
6444517269195.084,"[256, 1, 1]",7,0,4.128,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1718,X,3.333333,0,kernel,26.666666,"[7, 8, 5]",56,296
6444517269203.468,"[256, 1, 1]",7,0,11.776,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1720,X,48.761906,0,kernel,390.095245,"[1, 8, 512]",100,296
6444517269223.724,"[128, 1, 1]",7,0,8.224,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,148,98304,7,1725,X,0.380952,0,kernel,1.52381,"[8, 4, 1]",0,296
6444517269234.028,"[256, 1, 1]",7,0,2.112,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1728,X,1.904762,0,kernel,15.238095,"[2, 16, 5]",32,296
6444517269298.892,"[128, 1, 1]",7,0,1.472,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1736,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,297
6444517269438.317,"[512, 1, 1]",7,0,8.512,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,2192,7,1789,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,300
6444517269473.069,"[128, 1, 1]",7,0,2.24,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",1,0,22,0,7,1796,X,2.916667,0,kernel,11.666667,"[245, 1, 1]",24,308
6444517269517.42,"[128, 1, 1]",7,0,1.761,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1803,X,2.916667,0,kernel,11.666667,"[245, 1, 1]",24,310
6444517269643.597,"[256, 1, 1]",7,0,2.208,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1823,X,1.904762,0,kernel,15.238095,"[2, 16, 5]",32,314
6444517269650.989,"[256, 1, 1]",7,0,33.888,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1825,X,97.523811,0,kernel,780.190491,"[1, 16, 512]",100,314
6444517269688.013,"[128, 1, 1]",7,0,53.217,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,198,100352,7,1831,X,0.380952,0,kernel,1.52381,"[8, 2, 2]",0,314
6444517269741.933,"[256, 1, 1]",7,0,2.592,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1834,X,1.904762,0,kernel,15.238095,"[2, 16, 5]",32,314
6444517269757.069,"[128, 1, 1]",7,0,1.889,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1842,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,315
6444517269892.846,"[512, 1, 1]",7,0,8.64,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,2192,7,1895,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,318
6444517269942.83,"[128, 1, 1]",7,0,1.664,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1903,X,2.916667,0,kernel,11.666667,"[245, 1, 1]",24,327
6444517270170.478,"[256, 1, 1]",7,0,2.208,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1927,X,1.904762,0,kernel,15.238095,"[2, 16, 5]",32,331
6444517270178.51,"[256, 1, 1]",7,0,32.672,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1929,X,97.523811,0,kernel,780.190491,"[1, 16, 512]",100,331
6444517270214.286,"[128, 1, 1]",7,0,53.088,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,198,100352,7,1935,X,0.380952,0,kernel,1.52381,"[8, 2, 2]",0,331
6444517270268.174,"[256, 1, 1]",7,0,2.72,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1938,X,1.904762,0,kernel,15.238095,"[2, 16, 5]",32,331
6444517270297.582,"[128, 1, 1]",7,0,1.792,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1946,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,332
6444517270438.415,"[512, 1, 1]",7,0,8.64,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,2192,7,1999,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,335
6444517270474.831,"[128, 1, 1]",7,0,2.304,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",1,0,22,0,7,2006,X,2.916667,0,kernel,11.666667,"[245, 1, 1]",24,343
6444517270519.375,"[128, 1, 1]",7,0,1.696,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,2013,X,2.916667,0,kernel,11.666667,"[245, 1, 1]",24,345
6444517270648.783,"[32, 16, 1]",7,0,4.064,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4>)",1,0,32,16,7,2029,X,1.904762,0,kernel,30.476191,"[160, 1, 1]",63,347
6444517270851.6,"[128, 1, 1]",7,0,9.024,"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 6, 7, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",1,0,56,10752,7,2048,X,1.488095,0,kernel,5.952381,"[125, 1, 1]",12,354
