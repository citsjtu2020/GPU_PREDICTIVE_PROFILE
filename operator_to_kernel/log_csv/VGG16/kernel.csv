ts,block,tid,queued,dur,name,context,device,registers per thread,shared memory,stream,correlation,ph,blocks per SM,pid,cat,warps per SM,grid,est. achieved occupancy %,External id
6083647120702.857,"[256, 1, 1]",7,0,2.209,"void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams)",1,0,16,0,7,15,X,2.345238,0,kernel,18.761906,"[197, 1, 1]",39,5
6083647120705.801,"[128, 1, 1]",7,0,39.52,_5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1,1,0,128,16384,7,18,X,4.666667,0,kernel,18.666666,"[392, 1, 1]",33,5
6083647120746.122,"[128, 1, 1]",7,0,46.015,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,26,X,149.333328,0,kernel,597.333313,"[12544, 1, 1]",100,8
6083647120792.905,"[128, 1, 1]",7,0,2.272,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,32,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,9
6083647120795.913,"[512, 1, 1]",7,0,64.096,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,40,144,7,84,X,0.761905,0,kernel,12.190476,"[64, 1, 1]",25,12
6083647120907.945,"[128, 1, 1]",7,0,46.368,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,104,X,74.666664,0,kernel,298.666656,"[6272, 1, 1]",100,25
6083647120955.113,"[32, 4, 1]",7,0,3.136,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",1,0,40,8704,7,127,X,0.380952,0,kernel,1.52381,"[2, 16, 1]",3,30
6083647120959.049,"[256, 1, 1]",7,0,144.192,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,1,0,126,49152,7,129,X,9.333333,0,kernel,74.666664,"[2, 28, 14]",33,30
6083647121104.137,"[128, 1, 1]",7,0,46.016,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,137,X,149.333328,0,kernel,597.333313,"[12544, 1, 1]",100,33
6083647121150.857,"[128, 1, 1]",7,0,2.112,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,143,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,34
6083647121153.736,"[512, 1, 1]",7,0,64.705,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,40,144,7,195,X,0.761905,0,kernel,12.190476,"[64, 1, 1]",25,37
6083647121265.929,"[128, 1, 1]",7,0,46.271,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,215,X,74.666664,0,kernel,298.666656,"[6272, 1, 1]",100,50
6083647121313.0,"[256, 1, 1]",7,0,44.417,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,26,0,7,234,X,37.333332,0,kernel,298.666656,"[3136, 1, 1]",100,53
6083647121358.216,"[256, 1, 1]",7,0,10.336,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,252,X,9.333333,0,kernel,74.666664,"[392, 2, 1]",100,57
6083647121369.352,"[256, 1, 1]",7,0,4.0,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,254,X,3.047619,0,kernel,24.380953,"[1, 2, 128]",51,57
6083647121374.12,"[256, 1, 1]",7,0,62.336,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize256x128x32_stage2_warpsize4x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,254,98304,7,259,X,0.583333,0,kernel,4.666667,"[1, 49, 1]",0,57
6083647121437.608,"[128, 1, 1]",7,0,17.568,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,268,X,74.666664,0,kernel,298.666656,"[6272, 1, 1]",100,60
6083647121455.912,"[128, 1, 1]",7,0,2.24,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,274,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,61
6083647121458.952,"[512, 1, 1]",7,0,22.048,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,40,144,7,326,X,1.52381,0,kernel,24.380953,"[128, 1, 1]",51,64
6083647121505.8,"[128, 1, 1]",7,0,23.552,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,346,X,37.333332,0,kernel,149.333328,"[3136, 1, 1]",100,77
6083647121530.152,"[256, 1, 1]",7,0,21.376,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,368,X,18.666666,0,kernel,149.333328,"[392, 4, 1]",100,82
6083647121552.712,"[256, 1, 1]",7,0,4.96,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,370,X,6.095238,0,kernel,48.761906,"[1, 4, 128]",100,82
6083647121560.872,"[128, 1, 1]",7,0,102.08,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,230,49152,7,374,X,2.333333,0,kernel,9.333333,"[1, 98, 2]",17,82
6083647121663.752,"[128, 1, 1]",7,0,20.384,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,383,X,74.666664,0,kernel,298.666656,"[6272, 1, 1]",100,85
6083647121684.936,"[128, 1, 1]",7,0,2.304,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,389,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,86
6083647121688.136,"[512, 1, 1]",7,0,22.24,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,40,144,7,441,X,1.52381,0,kernel,24.380953,"[128, 1, 1]",51,89
6083647121735.208,"[128, 1, 1]",7,0,24.0,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,461,X,37.333332,0,kernel,149.333328,"[3136, 1, 1]",100,102
6083647121759.943,"[256, 1, 1]",7,0,20.48,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,26,0,7,480,X,18.666666,0,kernel,149.333328,"[1568, 1, 1]",100,105
6083647121781.16,"[256, 1, 1]",7,0,4.736,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,498,X,4.666667,0,kernel,37.333332,"[98, 4, 1]",78,109
6083647121786.663,"[256, 1, 1]",7,0,6.945,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,500,X,12.190476,0,kernel,97.523811,"[1, 4, 256]",100,109
6083647121794.343,"[128, 1, 1]",7,0,53.28,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,230,49152,7,503,X,0.595238,0,kernel,2.380952,"[2, 25, 1]",5,109
6083647121848.52,"[128, 1, 1]",7,0,6.943,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,512,X,37.333332,0,kernel,149.333328,"[3136, 1, 1]",100,112
6083647121856.264,"[128, 1, 1]",7,0,1.983,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,518,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,113
6083647121859.143,"[512, 1, 1]",7,0,11.232,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,14480,7,571,X,3.047619,0,kernel,48.761906,"[256, 1, 1]",100,116
6083647121880.775,"[128, 1, 1]",7,0,6.657,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,592,X,18.666666,0,kernel,74.666664,"[1568, 1, 1]",100,129
6083647121888.263,"[256, 1, 1]",7,0,7.488,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,614,X,9.333333,0,kernel,74.666664,"[98, 8, 1]",100,134
6083647121896.519,"[256, 1, 1]",7,0,11.072,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,616,X,24.380953,0,kernel,195.047623,"[1, 8, 256]",100,134
6083647121910.536,"[128, 1, 1]",7,0,83.967,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,230,49152,7,620,X,4.761905,0,kernel,19.047619,"[2, 25, 8]",17,134
6083647121995.367,"[128, 1, 1]",7,0,7.296,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,629,X,37.333332,0,kernel,149.333328,"[3136, 1, 1]",100,137
6083647122003.399,"[128, 1, 1]",7,0,1.952,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,635,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,138
6083647122006.119,"[512, 1, 1]",7,0,10.56,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,14480,7,688,X,3.047619,0,kernel,48.761906,"[256, 1, 1]",100,141
6083647122026.695,"[128, 1, 1]",7,0,7.168,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,709,X,18.666666,0,kernel,74.666664,"[1568, 1, 1]",100,154
6083647122034.631,"[256, 1, 1]",7,0,6.464,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,731,X,9.333333,0,kernel,74.666664,"[98, 8, 1]",100,159
6083647122041.895,"[256, 1, 1]",7,0,10.784,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,733,X,24.380953,0,kernel,195.047623,"[1, 8, 256]",100,159
6083647122056.007,"[128, 1, 1]",7,0,88.416,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,230,49152,7,737,X,4.761905,0,kernel,19.047619,"[2, 25, 8]",17,159
6083647122145.255,"[128, 1, 1]",7,0,7.616,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,746,X,37.333332,0,kernel,149.333328,"[3136, 1, 1]",100,162
6083647122153.735,"[128, 1, 1]",7,0,1.92,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,752,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,163
6083647122156.423,"[512, 1, 1]",7,0,10.112,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,14480,7,805,X,3.047619,0,kernel,48.761906,"[256, 1, 1]",100,166
6083647122176.583,"[128, 1, 1]",7,0,6.944,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,826,X,18.666666,0,kernel,74.666664,"[1568, 1, 1]",100,179
6083647122184.423,"[256, 1, 1]",7,0,6.688,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,26,0,7,845,X,9.333333,0,kernel,74.666664,"[784, 1, 1]",100,182
6083647122191.847,"[256, 1, 1]",7,0,2.464,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,863,X,2.380952,0,kernel,19.047619,"[25, 8, 1]",40,186
6083647122195.111,"[256, 1, 1]",7,0,18.848,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,865,X,48.761906,0,kernel,390.095245,"[1, 8, 512]",100,186
6083647122214.695,"[128, 1, 1]",7,0,51.168,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params),1,0,162,73728,7,869,X,0.666667,0,kernel,2.666667,"[28, 2, 1]",0,186
6083647122266.631,"[256, 1, 1]",7,0,3.392,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,873,X,4.761905,0,kernel,38.095238,"[25, 16, 1]",79,186
6083647122270.855,"[128, 1, 1]",7,0,4.512,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,881,X,18.666666,0,kernel,74.666664,"[1568, 1, 1]",100,189
6083647122276.135,"[128, 1, 1]",7,0,1.568,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,887,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,190
6083647122278.503,"[512, 1, 1]",7,0,9.856,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,4240,7,940,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,193
6083647122292.423,"[128, 1, 1]",7,0,2.431,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,961,X,9.333333,0,kernel,37.333332,"[784, 1, 1]",78,206
6083647122295.591,"[256, 1, 1]",7,0,2.976,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,983,X,4.761905,0,kernel,38.095238,"[25, 16, 1]",79,211
6083647122299.366,"[256, 1, 1]",7,0,33.857,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,985,X,97.523811,0,kernel,780.190491,"[1, 16, 512]",100,211
6083647122333.959,"[128, 1, 1]",7,0,96.063,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),1,0,168,73728,7,989,X,0.666667,0,kernel,2.666667,"[28, 2, 1]",0,211
6083647122430.854,"[256, 1, 1]",7,0,3.424,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,993,X,4.761905,0,kernel,38.095238,"[25, 16, 1]",79,211
6083647122435.11,"[128, 1, 1]",7,0,4.096,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,1001,X,18.666666,0,kernel,74.666664,"[1568, 1, 1]",100,214
6083647122440.07,"[128, 1, 1]",7,0,1.601,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1007,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,215
6083647122442.47,"[512, 1, 1]",7,0,9.728,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,4240,7,1060,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,218
6083647122456.326,"[128, 1, 1]",7,0,2.433,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1081,X,9.333333,0,kernel,37.333332,"[784, 1, 1]",78,231
6083647122459.494,"[256, 1, 1]",7,0,2.976,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1103,X,4.761905,0,kernel,38.095238,"[25, 16, 1]",79,236
6083647122463.27,"[256, 1, 1]",7,0,34.016,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1105,X,97.523811,0,kernel,780.190491,"[1, 16, 512]",100,236
6083647122498.054,"[128, 1, 1]",7,0,95.648,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),1,0,168,73728,7,1109,X,0.666667,0,kernel,2.666667,"[28, 2, 1]",0,236
6083647122594.47,"[256, 1, 1]",7,0,3.296,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1113,X,4.761905,0,kernel,38.095238,"[25, 16, 1]",79,236
6083647122598.566,"[128, 1, 1]",7,0,4.192,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,1121,X,18.666666,0,kernel,74.666664,"[1568, 1, 1]",100,239
6083647122603.526,"[128, 1, 1]",7,0,1.536,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1127,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,240
6083647122605.894,"[512, 1, 1]",7,0,9.952,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,4240,7,1180,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,243
6083647122619.974,"[128, 1, 1]",7,0,2.432,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1201,X,9.333333,0,kernel,37.333332,"[784, 1, 1]",78,256
6083647122623.142,"[256, 1, 1]",7,0,4.096,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,26,0,7,1220,X,4.666667,0,kernel,37.333332,"[392, 1, 1]",78,259
6083647122627.942,"[256, 1, 1]",7,0,2.176,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1238,X,1.333333,0,kernel,10.666667,"[7, 16, 1]",22,263
6083647122630.854,"[256, 1, 1]",7,0,33.856,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1240,X,97.523811,0,kernel,780.190491,"[1, 16, 512]",100,263
6083647122667.27,"[128, 1, 1]",7,0,38.4,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,198,100352,7,1246,X,0.761905,0,kernel,3.047619,"[8, 2, 4]",0,263
6083647122706.406,"[256, 1, 1]",7,0,2.752,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1249,X,1.333333,0,kernel,10.666667,"[7, 16, 1]",22,263
6083647122710.054,"[128, 1, 1]",7,0,2.944,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,1257,X,4.666667,0,kernel,18.666666,"[392, 1, 1]",39,266
6083647122713.894,"[128, 1, 1]",7,0,1.568,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1263,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,267
6083647127310.301,"[512, 1, 1]",7,0,9.793,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,2192,7,1316,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,270
6083647127323.901,"[128, 1, 1]",7,0,1.728,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1337,X,2.333333,0,kernel,9.333333,"[196, 1, 1]",19,283
6083647127326.397,"[256, 1, 1]",7,0,2.144,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1359,X,1.333333,0,kernel,10.666667,"[7, 16, 1]",22,288
6083647127329.405,"[256, 1, 1]",7,0,33.952,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1361,X,97.523811,0,kernel,780.190491,"[1, 16, 512]",100,288
6083647127366.621,"[128, 1, 1]",7,0,38.56,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,198,100352,7,1367,X,0.761905,0,kernel,3.047619,"[8, 2, 4]",0,288
6083647127405.949,"[256, 1, 1]",7,0,2.88,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1370,X,1.333333,0,kernel,10.666667,"[7, 16, 1]",22,288
6083647127409.629,"[128, 1, 1]",7,0,2.848,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,1378,X,4.666667,0,kernel,18.666666,"[392, 1, 1]",39,291
6083647127413.277,"[128, 1, 1]",7,0,1.568,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1384,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,292
6083647127415.645,"[512, 1, 1]",7,0,8.704,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,2192,7,1437,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,295
6083647127427.581,"[128, 1, 1]",7,0,1.696,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1458,X,2.333333,0,kernel,9.333333,"[196, 1, 1]",19,308
6083647127430.109,"[256, 1, 1]",7,0,2.112,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1480,X,1.333333,0,kernel,10.666667,"[7, 16, 1]",22,313
6083647127433.469,"[256, 1, 1]",7,0,33.184,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,38,4224,7,1482,X,97.523811,0,kernel,780.190491,"[1, 16, 512]",100,313
6083647127469.981,"[128, 1, 1]",7,0,38.496,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,198,100352,7,1488,X,0.761905,0,kernel,3.047619,"[8, 2, 4]",0,313
6083647127509.629,"[256, 1, 1]",7,0,2.464,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,40,4224,7,1491,X,1.333333,0,kernel,10.666667,"[7, 16, 1]",22,313
6083647127512.861,"[128, 1, 1]",7,0,2.88,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,16,0,7,1499,X,4.666667,0,kernel,18.666666,"[392, 1, 1]",39,316
6083647127516.541,"[128, 1, 1]",7,0,1.568,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,24,0,7,1505,X,0.011905,0,kernel,0.047619,"[1, 1, 1]",0,317
6083647127518.909,"[512, 1, 1]",7,0,8.672,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,40,2192,7,1558,X,6.095238,0,kernel,97.523811,"[512, 1, 1]",100,320
6083647127531.005,"[128, 1, 1]",7,0,1.664,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,18,0,7,1579,X,2.333333,0,kernel,9.333333,"[196, 1, 1]",19,333
6083647127533.533,"[256, 1, 1]",7,0,2.72,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,26,0,7,1598,X,1.166667,0,kernel,9.333333,"[98, 1, 1]",19,336
6083647127537.117,"[32, 4, 1]",7,0,692.991,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",1,0,159,528,7,1617,X,12.190476,0,kernel,48.761906,"[1024, 1, 1]",25,342
6083647128230.94,"[256, 1, 1]",7,0,2.368,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",1,0,47,0,7,1648,X,0.190476,0,kernel,1.52381,"[16, 1, 1]",3,344
6083647128234.14,"[128, 1, 1]",7,0,115.807,"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, false, true, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>, float, float)",1,0,58,2560,7,1667,X,6.095238,0,kernel,24.380953,"[512, 1, 1]",51,353
6083647128350.779,"[256, 1, 1]",7,0,3.265,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",1,0,47,0,7,1698,X,0.190476,0,kernel,1.52381,"[16, 1, 1]",3,355
6083647128354.875,"[32, 4, 1]",7,0,30.336,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",1,0,159,528,7,1717,X,2.976191,0,kernel,11.904762,"[250, 1, 1]",25,364
