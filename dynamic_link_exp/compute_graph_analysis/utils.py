import pandas as pd
import torch
import torch.fx
from typing import Optional,List

from torch.fx.node import _type_repr,_format_arg
from torch.fx import Node,Graph
# from compute_graph_analysis.qualified_tracer import QualifiedTracer
from compute_graph_analysis.prop_interpreter import TensorMetadata

def catch_up_down_node(node: torch.fx.Node,mode=0):
    if (mode<1):
        tmp_edges = node._input_nodes
    else:
        tmp_edges = node.users

    # print(len(tmp_edges))

    res_n = []
    for n in tmp_edges.keys():
        res_n.append(n.name)

    res_s_str = "["

    if len(res_n) > 0:

        for rd_id in range(len(res_n)):
            if rd_id < (len(res_n) - 1):
                res_s_str += res_n[rd_id] + ","
            else:
                res_s_str += res_n[rd_id]

    res_s_str += "]"

    return res_s_str








def catch_node_basic_prop(node: Node,
                placeholder_names: Optional[List[str]] = None,
                maybe_return_typename: Optional[List[str]] = None):
    """
    Return a descriptive string representation of ``self``.

    This method can be used with no arguments as a debugging
    utility.

    This function is also used internally in the ``__str__`` method
    of ``Graph``. Together, the strings in ``placeholder_names``
    and ``maybe_return_typename`` make up the signature of the
    autogenerated ``forward`` function in this Graph's surrounding
    GraphModule. ``placeholder_names`` and ``maybe_return_typename``
    should not be used otherwise.

    Args:
        placeholder_names: A list that will store formatted strings
            representing the placeholders in the generated
            ``forward`` function. Internal use only.
        maybe_return_typename: A single-element list that will store
            a formatted string representing the output of the
            generated ``forward`` function. Internal use only.

    Returns:
        str: If 1) we're using ``format_node`` as an internal helper
            in the ``__str__`` method of ``Graph``, and 2) ``self``
            is a placeholder Node, return ``None``. Otherwise,
            return a  descriptive string representation of the
            current Node.
    """
    res_dict = {}
    res_dict["op_type"] = node.op
    res_dict["name"] = node.name
    res_dict["num_downstream"] = len(node.users)
    res_dict["num_upstream"] = len(node._input_nodes)

    res_dict["downstream"] = catch_up_down_node(node,mode=2)
    res_dict["upstream"] = catch_up_down_node(node,mode=0)

    if node.op == 'placeholder':
        assert isinstance(node.target, str)
        arg_str = node.target
        arg_str += arg_str + f': {_type_repr(node.type)}' if node.type else ''
        if placeholder_names:
            placeholder_names.append(arg_str)
            return {}

        maybe_typename = f'{_type_repr(node.type)} ' if node.type else ''
        default_val = str(node.args[0]) if node.args else ''

        # self._input_nodes

        res_dict["target"] = node.target
        res_dict["default_val"] = default_val
        res_dict["args"] = "()"
        res_dict["kwargs"] = "{}"


    elif node.op == 'get_attr':

        res_dict["target"] = f'{node._pretty_print_target(node.target)}'
        res_dict["default_val"] = None
        res_dict["args"] = "()"
        res_dict["kwargs"] = "{}"


    elif node.op == 'output':
        res_dict["target"] = f'output f{node.args[0]}'
        res_dict["default_val"] = None
        res_dict["args"] = f"({node.args[0],})"
        res_dict["kwargs"] = "{}"

    else:
        res_dict["target"] = f'{node._pretty_print_target(node.target)}'
        res_dict["default_val"] = None
        res_dict["args"] = f"{_format_arg(node.args)}"
        res_dict["kwargs"] = f"{_format_arg(node.kwargs)}"

    return res_dict

def catch_graph_basic_prop(graph: Graph):
    out_res = {}
    for node in graph.nodes:
        tmp_res = catch_node_basic_prop(node)
        for k, v in tmp_res.items():
            if k not in out_res.keys():
                out_res[k] = []
            out_res[k].append(v)

    out_res_pdf = pd.DataFrame(out_res)
    return out_res_pdf


def catch_node_tensor_prop(node: Node, aim_meta_list=["shape", "dtype"]):
    out_result = {"op_type": [node.op], "name": [node.name]}
    qparam_key = ["qscheme", "scale", "zero_point", "axis"]
    # valid_metas = ["shape","dtype","requires_grad","stride","memory_format","is_quantized","qparams"]
    # "qscheme","scale","zero_point","axis"
    for aml in aim_meta_list:
        if "params" not in aml:
            out_result[aml] = []
        else:
            for q in qparam_key:
                out_result[q] = []

    if "tensor_meta" in node.meta.keys():
        tmp_tensor_meta: TensorMetadata = node.meta["tensor_meta"]
        if "shape" in aim_meta_list:
            out_result["shape"].append(tuple(tmp_tensor_meta.shape))
        if "dtype" in aim_meta_list:
            out_result["dtype"].append(tmp_tensor_meta.dtype)
        if "requires_grad" in aim_meta_list:
            out_result["requires_grad"].append(tmp_tensor_meta.requires_grad)
        if "stride" in aim_meta_list:
            out_result["stride"].append(tmp_tensor_meta.stride)
        if "memory_format" in aim_meta_list:
            out_result["memory_format"].append(tmp_tensor_meta.memory_format)
        if "is_quantized" in aim_meta_list:
            out_result["is_quantized"].append(tmp_tensor_meta.is_quantized)
        if "qparams" in aim_meta_list:
            for qpk in qparam_key:
                if qpk not in tmp_tensor_meta.qparams.keys():
                    out_result[qpk] = None
                else:
                    out_result[qpk] = tmp_tensor_meta.qparams[qpk]
    else:
        for aml in out_result.keys():
            if aml not in ["op_type","name"]:
                out_result[aml].append(None)
    # print(out_result)
    out_result_pdf = pd.DataFrame(out_result)
    return out_result_pdf

def traverse_submodules(module:torch.nn.Module,base_prefix=""):
    # if len(list(module.named_children())) == 0:
    #     module_decomped = {}
    module_decomped = {}
    now_prefix = base_prefix
    for submodule in module.named_children():
        print((submodule))
        print(type(submodule[1]))
        if len(list(submodule[1].named_children()))==0:
            if now_prefix:
                module_decomped[f"{now_prefix}.{submodule[0]}"] = submodule[1].__str__()
            else:
                module_decomped[f"{submodule[0]}"] = submodule[1].__str__()
        else:
            # module_decomped[submodule[0]] = {}
            if now_prefix:
                add_module_decomped = traverse_submodules(submodule[1],base_prefix=f"{now_prefix}.{submodule[0]}")
            else:
                add_module_decomped = traverse_submodules(submodule[1], base_prefix=f"{submodule[0]}")
            for amdk in add_module_decomped.keys():
                module_decomped[amdk] = add_module_decomped[amdk]

    return module_decomped




